{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO_7092 Evaluation of Machine Learning Methods 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Student name: Arvin Jalali\n",
    "\n",
    "Student number: 2310744\n",
    "\n",
    "Student email: arvin.a.jalali@utu.fi\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Complete the tasks given to you in the letter below. In your submission, explain clearly, precisely, and comprehensively why the cross-validation described in the letter failed, how cross-validation should be performed in the given scenario and why  your cross-validation will give a reliable estimate of the generalisation performance. Then implement the correct cross-validation for the scenario and report its results.\n",
    "\n",
    "Remember to follow all the general exercise guidelines that are stated in Moodle. Full points (2p) will be given for a submission that demonstrates a deep understanding of cross-validation on pair-input data and implements the requested cross-validation correctly (incl. reporting the results). Partial points (1p) will be given if there are small error(s) but the overall approach is correct. No points will be given if there are significant error(s).\n",
    "\n",
    "The deadline of this exercise is **Wednesday 21 February 2024 at 11:59 PM**. Please contact Juho Heimonen (juaheim@utu.fi) if you have any questions about this exercise.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Data Scientist,\n",
    "\n",
    "I have a long-term research project regarding a specific set of proteins. Currently I am attempting to discover small organic compounds that can bind strongly to these proteins and thus act as drugs. I have a list of over 100.000 potential drug molecules, but their affinities still need to be verified in the lab. Obviously I do not have the resources to measure all the possible drug-target pairs, so I need to prioritise. I have decided to do this with the use of machine learning, but I have encountered a problem.\n",
    "\n",
    "Here is what I have done so far: First I trained a K-nearest neighbours regressor with the parameter value K=10 using all the 400 measurements I had made in the lab, which comprise of all the 77 target proteins of interest but only 59 different drug molecules. Then I performed a leave-one-out cross-validation with this same data to estimate the generalisation performance of the model. I used C-index and got a stellar score above 90%. Finally I used the model to predict the affinities of the remaining drug molecules. The problem is: when I selected the highest predicted affinities and tried to verify them in the lab, I found that many of them are much lower in reality. My model clearly does not work despite the high cross-validation score.\n",
    "\n",
    "Please explain why my estimation failed and how leave-one-out cross-validation should be performed to get a reliable estimate. Also, implement the correct leave-one-out cross-validation and report its results. I need to know whether I am wasting my lab resources by using my model.\n",
    "\n",
    "The data I used to create my model is available in the files `input.data`, `output.data` and `pairs.data` for you to use. The first file contains the features of the pairs, whereas the second contains their affinities. The third file contains the identifiers of the drug and target molecules of which the pairs are composed. The files are paired, i.e. the i<sup>*th*</sup> row in each file is about the same pair.\n",
    "\n",
    "Looking forward to hearing from you soon.\n",
    "\n",
    "Yours sincerely, \\\n",
    "Bio Scientist\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the questions about cross-validation on pair-input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why did the estimation described in the letter fail?\n",
    "# How should leave-one-out cross-validation be performed in the given scenario and why?\n",
    "# Remember to provide comprehensive and precise arguments.\n",
    "We should pay much attention to dependencies in pair-input data, since the shared objects lead to dependencies between observations. Dependencies must be taken into account by performance evaluation methods. That is why the estimation described in the letter fails. Pair-input observations are not independent because objects are shared between observations.Drug and target molecules are paired in various combinations in drug-target interaction data as pair-input data.\r\n",
    "\r\n",
    "There 4 different types of pair-input observations, based on their type, different dependencies happen on the estimation of out-of-sample prediction performance. \r\n",
    "\r\n",
    "In type A, both members are in-sample objects. The performnace on type A observations can be appropriately estimated by the regular leave-one-out cross-validation. There are no restrictions on the objects that can appear in the training set. \r\n",
    "\r\n",
    "In type B, the first member is out-of-sample object, and the second member is in-sample object. Regarding the estimation for type B, in each fold, the observations that share the first pair member with the test observation must not be used for training. The first pair members of the test observation are not allowed to appear in the training set. \r\n",
    "\r\n",
    "In type C, the first member is in-sample object, and the second member is out-of-sample object. Regarding the estimation for type C, in each fold, the observations that share the second pair member with the test observation must not be used for training. The second pair members of the test observations are not allowed to appear in the training set.\r\n",
    "\r\n",
    "In type D, both members are out-of-sample objects. Regarding the estimation for type D, in each forld, the observations that share either pair members with the test observation must not be used for training. None of the pair members of the test observations are allowed to appear in training set.\r\n",
    "\r\n",
    "The 4 types of out-of-sample observations differe by the nature and extent of dependencies. Out-of-sample prediction performance must be estimated separately for each type. \r\n",
    "\r\n",
    "In this exercise, it has been mentioned: \"which comprise of all the 77 target proteins of interest but only 59 different drug molecules\" . I can conclude that, there can be additional drug molecules other than the 59 molecules, which may appear in a pair-input observation as out-of-sample for the purpose of affinity prediction. In this case, considering the the order of pairs as (D - T), just like as data points in the pairs.data, then that is type B pair-input data. In my opinion, in this exercise type C and D cannot happen, becuase it has mentioned in the letter that, all of 77 targets have utilized. So in this assignment, leave-one-out cross-validation for type A (regular one) and most importantly for type B separately should be implemented. In case of not implementing a separate cross-validation for type B, and C, D (if required), serious dependencies caused by shared objects among observations lead to unreliable C_index as performance metric, meaning that the value of C_index looks really good, but it is not real, and of course that is very unreliable. By making separate cross-validation for types B, C, D, we actually modify the training set for each type by removing some observations affected by dependencies due to shared objects in pair-input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries you need.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the utility functions you need in your analysis.\n",
    "\n",
    "\"\"\"\n",
    "C-index function: \n",
    "- INPUTS: \n",
    "'y' an array of the true output values\n",
    "'yp' an array of predicted output values\n",
    "- OUTPUT: \n",
    "The c-index value\n",
    "\"\"\"\n",
    "def cindex(y, yp):\n",
    "    n = 0\n",
    "    h_num = 0 \n",
    "    for i in range(0, len(y)):\n",
    "        t = y[i]\n",
    "        p = yp[i]\n",
    "        for j in range(i+1, len(y)):\n",
    "            nt = y[j]\n",
    "            np = yp[j]\n",
    "            if (t != nt): \n",
    "                n = n + 1\n",
    "                if (p < np and t < nt) or (p > np and t > nt): \n",
    "                    h_num += 1\n",
    "                elif (p == np):\n",
    "                    h_num += 0.5\n",
    "    return h_num/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the dimensions of input.data and output.data respectively\n",
      "(400, 67)\n",
      "(400, 1)\n",
      "Here is the dimension of pairs.data\n",
      "(400, 2)\n",
      "         0      1\n",
      "0    \"D40\"   \"T2\"\n",
      "1    \"D31\"  \"T64\"\n",
      "2     \"D6\"  \"T58\"\n",
      "3    \"D56\"  \"T49\"\n",
      "4    \"D20\"  \"T28\"\n",
      "..     ...    ...\n",
      "395  \"D30\"  \"T27\"\n",
      "396  \"D53\"  \"T11\"\n",
      "397  \"D29\"  \"T27\"\n",
      "398  \"D53\"  \"T50\"\n",
      "399   \"D4\"  \"T15\"\n",
      "\n",
      "[400 rows x 2 columns]\n",
      "\n",
      "Collection of drug items: {'D13', 'D31', 'D43', 'D29', 'D2', 'D37', 'D4', 'D25', 'D35', 'D11', 'D23', 'D21', 'D36', 'D40', 'D12', 'D47', 'D32', 'D46', 'D7', 'D48', 'D15', 'D50', 'D10', 'D14', 'D55', 'D54', 'D56', 'D42', 'D9', 'D44', 'D5', 'D24', 'D34', 'D53', 'D27', 'D57', 'D28', 'D20', 'D8', 'D26', 'D45', 'D38', 'D6', 'D17', 'D59', 'D1', 'D16', 'D18', 'D41', 'D3', 'D22', 'D30', 'D19', 'D51', 'D39', 'D58', 'D52', 'D49', 'D33'}\n",
      "\n",
      "Collection of target items: {'T71', 'T67', 'T30', 'T59', 'T35', 'T76', 'T40', 'T45', 'T57', 'T27', 'T47', 'T13', 'T63', 'T22', 'T37', 'T52', 'T18', 'T2', 'T36', 'T28', 'T53', 'T64', 'T68', 'T1', 'T46', 'T7', 'T25', 'T10', 'T5', 'T58', 'T69', 'T42', 'T24', 'T75', 'T38', 'T50', 'T73', 'T17', 'T21', 'T66', 'T72', 'T70', 'T9', 'T54', 'T31', 'T65', 'T11', 'T39', 'T48', 'T44', 'T55', 'T61', 'T12', 'T62', 'T26', 'T23', 'T74', 'T33', 'T16', 'T77', 'T20', 'T8', 'T43', 'T41', 'T3', 'T34', 'T15', 'T4', 'T32', 'T51', 'T14', 'T19', 'T56', 'T49', 'T29', 'T60', 'T6'}\n",
      "\n",
      "number of drug items: 59\n",
      "number of target items: 77\n"
     ]
    }
   ],
   "source": [
    "# Read the data files (input.data, output.data, pairs.data).\n",
    "\n",
    "# Read input data\n",
    "input_df = pd.read_csv('input.data', header=None, delimiter=' ')\n",
    "output_df = pd.read_csv('output.data', header=None, delimiter=' ')\n",
    "print(\"Here are the dimensions of input.data and output.data respectively\")\n",
    "print(input_df.shape)\n",
    "print(output_df.shape)\n",
    "\n",
    "df = pd.read_csv('pairs.data', header=None, delimiter=' ', quoting=3)\n",
    "print(\"Here is the dimension of pairs.data\")\n",
    "print(df.shape)\n",
    "print(df)\n",
    "D_collection = set()\n",
    "T_collection = set()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    D_item = row[0].strip('\"')\n",
    "    T_item = row[1].strip('\"')\n",
    "    D_collection.add(D_item)\n",
    "    T_collection.add(T_item)\n",
    "\n",
    "print()\n",
    "print(\"Collection of drug items:\", D_collection)\n",
    "print()\n",
    "print(\"Collection of target items:\", T_collection)\n",
    "\n",
    "print()\n",
    "print(\"number of drug items:\", len(D_collection))\n",
    "print(\"number of target items:\", len(T_collection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement and run cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_index for type B pair-input data with KNN, K=10 is equal to: 0.51968671679198\n",
      "C_index for type A pair-input data with KNN, K=10 is equal to: 0.8300062656641604\n"
     ]
    }
   ],
   "source": [
    "# implementing leave one out cross validation for type B and comparing the C_index with type A\n",
    "X = input_df.values\n",
    "y = output_df.values\n",
    "df_array = df.values\n",
    "\n",
    "# a function which gets a pair-input and return the type of the given pair-input.\n",
    "# such a function is not really required for this assignment.\n",
    "def check_availability(drug_item, target_item):\n",
    "    \n",
    "    if drug_item in D_collection and target_item in T_collection:\n",
    "        return \"A\"\n",
    "    elif drug_item in D_collection and target_item not in T_collection:\n",
    "        return \"B\"\n",
    "    elif drug_item not in D_collection and target_item in T_collection:\n",
    "        return \"C\"\n",
    "    else:\n",
    "        return \"D\"\n",
    "        \n",
    "# result = check_availability('D310', 'T150')\n",
    "\n",
    "\n",
    "# This a function which returns the indexes of observations should be removed from traing set\n",
    "# particularly for TYPE B pair-input leave one out cross validation\n",
    "def find_matching_indexes(index, data):\n",
    "    target_value = data[index][0]  # Get the value of the first feature at the given index\n",
    "    matching_indexes = [i for i, row in enumerate(data) if row[0] == target_value]\n",
    "    return matching_indexes\n",
    "    \n",
    "\n",
    "def pair_data_LOO_CV(X, y, n_neighbors):\n",
    "\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    y_preds = []\n",
    "    for i in range(len(X)):\n",
    "        indices_to_remove = find_matching_indexes(i, df_array)  # List of indexes to remove\n",
    "        X_train = np.delete(X, indices_to_remove, axis=0)\n",
    "        y_train = np.delete(y, indices_to_remove)\n",
    "        #X_train = np.delete(X, i, axis=0)\n",
    "        #y_train = np.delete(y, i)\n",
    "        X_test = X[i].reshape(1, -1)\n",
    "        y_test = y[i]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    y_preds = np.array(y_preds)\n",
    "    avg_cindex = cindex(y, y_preds)\n",
    "    \n",
    "    return avg_cindex\n",
    "    \n",
    "type_B_C_index = pair_data_LOO_CV(X, y, 10)\n",
    "print(\"C_index for type B pair-input data with KNN, K=10 is equal to:\", type_B_C_index)\n",
    "\n",
    "def LOO_CV(X, y, n_neighbors):\n",
    "\n",
    "    knn = KNeighborsRegressor(n_neighbors=n_neighbors)\n",
    "    y_preds = []\n",
    "    for i in range(len(X)):\n",
    "        X_train = np.delete(X, i, axis=0)\n",
    "        y_train = np.delete(y, i)\n",
    "        X_test = X[i].reshape(1, -1)\n",
    "        y_test = y[i]\n",
    "\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        y_preds.append(y_pred)\n",
    "\n",
    "    y_preds = np.array(y_preds)\n",
    "    avg_cindex = cindex(y, y_preds)\n",
    "    \n",
    "    return avg_cindex\n",
    "    \n",
    "type_A_C_index = LOO_CV(X, y, 10)\n",
    "print(\"C_index for type A pair-input data with KNN, K=10 is equal to:\", type_A_C_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
